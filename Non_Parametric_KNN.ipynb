{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training data set\n",
    "rawData=pd.read_csv(\"./all/train.csv\")\n",
    "#import test data set\n",
    "testData = pd.read_csv(\"./all/test.csv\")\n",
    "cleanTrain = pd.read_csv(\"../Jiangxue_code/JX_train_x.csv\")\n",
    "cleanTest = pd.read_csv(\"../Jiangxue_code/JX_test.csv\")\n",
    "dummyTraining = pd.read_csv(\"../Jiangxue_code/x_train_dummies.csv\")\n",
    "corrmat = rawData.corr()\n",
    "top = corrmat.nlargest(50, 'SalePrice').index  # Find the index of top 10 highest correlated variables\n",
    "d1 = pd.read_csv(\"x_train_no_log_no_sd.csv\")\n",
    "d2 =pd.read_csv(\"x_test_no_log_no_sd.csv\")\n",
    "salePrice = rawData.SalePrice \n",
    "newData = rawData[top[0:15]] #select the top 10 highest correlated variables\n",
    "newData.GarageYrBlt = newData.GarageYrBlt.fillna(value = newData.GarageYrBlt.median()) #fill missing data\n",
    "newData.MasVnrArea = newData.MasVnrArea.fillna(0)\n",
    "newData2 = newData.copy()\n",
    "# select attributes\n",
    "dataNew = SelectKBest(chi2,11).fit(newData2, salePrice) #use \n",
    "newData3 = newData2.iloc[:,dataNew.get_support()]\n",
    "# newData3 = newData3[newData3.SalePrice<650000]\n",
    "# newData3.iloc[:,1:10] = np.log(1+newData3.iloc[:,1:10])\n",
    "newData3.iloc[:,1:11] = preprocessing.StandardScaler().fit_transform(newData3.iloc[:,1:11]) #standardize the data\n",
    "colName = newData3.iloc[:,1:11].columns\n",
    "salePrice = np.log(1+np.array(newData3.SalePrice)) #logrithms\n",
    "newData3= np.array(newData3.iloc[:,1:11]) #convert the data into matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a func to calulate the rmsle \n",
    "def rmsle(y_pred, y_test) : \n",
    "    assert len(y_test) == len(y_pred)\n",
    "    return np.sqrt(np.mean((np.log(1+y_pred) - np.log(1+y_test))**2))\n",
    "def uniformKNN(myTest, trainingData, Y_train, k, prediction, testSet=None):\n",
    "    testLength = myTest.shape[0]\n",
    "    trainLenth = trainingData.shape[0]\n",
    "    #convert it into a matrix \n",
    "    Y_train = np.array(Y_train)\n",
    "    trainingData = np.array(trainingData)\n",
    "    myTest = np.array(myTest)\n",
    "    #matrix substraction and reshape\n",
    "    newArray = ((myTest[:,np.newaxis] - trainingData)**2).reshape(-1, myTest.shape[1])\n",
    "    #sum up each row\n",
    "    newArray2 = newArray.sum(axis=1)\n",
    "    #take square root\n",
    "    newArray2 = newArray2**(1/2)\n",
    "    #reshape the matrix\n",
    "    array2 = newArray2.reshape(testLength,trainLenth)\n",
    "    #sort each row and display by index\n",
    "    getIndex = np.argsort(array2)\n",
    "    #take the K nearest neighbors\n",
    "    getIndex2 = getIndex[:,:k]\n",
    "    Y_train = Y_train.reshape(1,-1)\n",
    "    #query the house price\n",
    "    housePrice = Y_train[0][getIndex2]\n",
    "    if prediction == \"Y\":\n",
    "        #take the average saleprice\n",
    "        return(housePrice.mean(axis=1))\n",
    "    elif prediction == \"N\":\n",
    "        return rmsle(housePrice.mean(axis=1),testSet)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013044329310786574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = newData3\n",
    "y = salePrice\n",
    "kf = KFold(n_splits=10,random_state=None, shuffle=True)\n",
    "AvgRsmle = []\n",
    "\n",
    "#K-fold cross validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    AvgRsmle.append(uniformKNN(X_test, X_train,y_train,8,\"N\",y_test))\n",
    "#print out the average RSMLE\n",
    "print(np.array(AvgRsmle).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighted KNN with manhantan distance\n",
    "def manhantanKNN(myTest, trainingData, Y_train, k, prediction, testSet=None):\n",
    "    testLength = myTest.shape[0]\n",
    "    trainLenth = trainingData.shape[0]\n",
    "    #convert it into a matrix \n",
    "    Y_train = np.array(Y_train)\n",
    "    trainingData = np.array(trainingData)\n",
    "    #matrix substraction and reshape\n",
    "    newArray = (np.abs(myTest[:,np.newaxis] - trainingData)).reshape(-1,myTest.shape[1])\n",
    "    #sum up each row\n",
    "    newArray2 = newArray.sum(axis=1)\n",
    "    #reshape the matrix\n",
    "    array2 = newArray2.reshape(testLength,trainLenth)\n",
    "    #sort each row and display by index\n",
    "    getIndex = np.argsort(array2)\n",
    "    #take the K nearest neighbors\n",
    "    getIndex2 = getIndex[:,:k]\n",
    "    weightsMatrix = np.sort(array2)\n",
    "    #create a weight matrix using the inverse of the distance\n",
    "    weights = weightsMatrix[:,:k]\n",
    "    weights[weights==0] =1\n",
    "    weights = weights**(-1)\n",
    "    Y_train = Y_train.reshape(1,-1)\n",
    "    #query the house price\n",
    "    housePrice = Y_train[0][getIndex2]\n",
    "    weightedHouseprice = weights*housePrice\n",
    "    if prediction == \"Y\":\n",
    "        #take the average saleprice\n",
    "        return (weightedHouseprice.sum(axis=1)/np.sum(weights,axis=1))\n",
    "    elif prediction == \"N\":\n",
    "        return rmsle(weightedHouseprice.sum(axis=1)/np.sum(weights,axis=1),testSet)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012678914329658866\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10,random_state=None, shuffle=True)\n",
    "AvgRsmle = []\n",
    "X = newData3\n",
    "y = salePrice\n",
    "#K-fold cross validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    AvgRsmle.append(manhantanKNN(X_test, X_train,y_train, 10,\"N\",y_test))\n",
    "print(np.array(AvgRsmle).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with manhantan distance and gaussian kernel\n",
    "def gaussianKernel(distance,lamda):\n",
    "    return np.exp(-(distance**2)/lamda)\n",
    "def KernelKNN(myTest, trainingData, Y_train, k, lamda,prediction, testSet=None):\n",
    "    testLength = myTest.shape[0]\n",
    "    trainLenth = trainingData.shape[0]\n",
    "    #convert it into a matrix \n",
    "    Y_train = np.array(Y_train)\n",
    "    trainingData = np.array(trainingData)\n",
    "    #matrix substraction and reshape\n",
    "\n",
    "    newArray = (np.abs(myTest[:,np.newaxis] - trainingData)).reshape(-1,myTest.shape[1])\n",
    "    #sum up each row\n",
    "    newArray2 = newArray.sum(axis=1)\n",
    "    #reshape the matrix\n",
    "    array2 = newArray2.reshape(testLength,trainLenth)\n",
    "    #sort each row and display by index\n",
    "    getIndex = np.argsort(array2)\n",
    "    #take the K nearest neighbors\n",
    "    getIndex2 = getIndex[:,:k]\n",
    "    weightsMatrix = np.sort(array2)\n",
    "    weights = weightsMatrix[:,:k]\n",
    "    weights =weights\n",
    "    newWeights = gaussianKernel(weights,lamda)\n",
    "    Y_train = Y_train.reshape(1,-1)\n",
    "    #query the house price\n",
    "    housePrice = Y_train[0][getIndex2]\n",
    "    weightedHouseprice = newWeights*housePrice\n",
    "    if prediction == \"Y\":\n",
    "        #take the average saleprice\n",
    "        return (weightedHouseprice.sum(axis=1)/np.sum(newWeights,axis=1))\n",
    "    elif prediction == \"N\":\n",
    "        return rmsle(weightedHouseprice.sum(axis=1)/np.sum(newWeights,axis=1),testSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "#K-fold cross validation\n",
    "kf = KFold(n_splits=10,random_state=None, shuffle=True)\n",
    "AvgRsmle = []\n",
    "X = newData3\n",
    "y = salePrice\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    AvgRsmle.append(KernelKNN(X_test, X_train,y_train, 8,0.1,\"N\",y_test))\n",
    "print(np.array(AvgRsmle).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predmean = KernelKNN(test3, X,y,15,0.1,\"Y\")\n",
    "# myId = pd.DataFrame(testData.Id)\n",
    "# prediction = pd.DataFrame(Predmean.reshape(-1,1), columns=[\"SalePrice\"])\n",
    "\n",
    "# prediciton2 = pd.concat([myId,prediction], axis=1,sort=False)\n",
    "# prediciton2.to_csv(\"Mysubmission1.csv\",index=False) #output it into a csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with euclidean distance and gaussian kernel\n",
    "def euclideanKNN(myTest, trainingData, Y_train, k,lamda, prediction, testSet=None):\n",
    "    testLength = myTest.shape[0]\n",
    "    trainLenth = trainingData.shape[0]\n",
    "    #convert it into a matrix \n",
    "    Y_train = np.array(Y_train)\n",
    "    trainingData = np.array(trainingData)\n",
    "    myTest = np.array(myTest)\n",
    "    #matrix substraction and reshape\n",
    "    newArray = ((myTest[:,np.newaxis] - trainingData)**2).reshape(-1, myTest.shape[1])\n",
    "    #sum up each row\n",
    "    newArray2 = newArray.sum(axis=1)\n",
    "    #take square root\n",
    "    newArray2 = newArray2**(1/2)\n",
    "    #reshape the matrix\n",
    "    array2 = newArray2.reshape(testLength,trainLenth)\n",
    "    #sort each row and display by index\n",
    "    getIndex = np.argsort(array2)\n",
    "    #take the K nearest neighbors\n",
    "    getIndex2 = getIndex[:,:k]\n",
    "    weightsMatrix = np.sort(array2)\n",
    "    weights = weightsMatrix[:,:k]\n",
    "    weights =weights\n",
    "#     weights = weights**(-1)\n",
    "    newWeights = gaussianKernel(weights,lamda)\n",
    "    Y_train = Y_train.reshape(1,-1)\n",
    "    #query the house price\n",
    "    housePrice = Y_train[0][getIndex2]\n",
    "    weightedHouseprice = newWeights*housePrice\n",
    "    if prediction == \"Y\":\n",
    "        #take the average saleprice\n",
    "        return (weightedHouseprice.sum(axis=1)/np.sum(newWeights,axis=1))\n",
    "    elif prediction == \"N\":\n",
    "        return rmsle(weightedHouseprice.sum(axis=1)/np.sum(newWeights,axis=1),testSet)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "#K-fold cross validation\n",
    "kf = KFold(n_splits=10,random_state=None, shuffle=True)\n",
    "AvgRsmle = []\n",
    "X = newData3\n",
    "y = salePrice\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    AvgRsmle.append(euclideanKNN(X_test, X_train,y_train, 10,0.1,\"N\",y_test))\n",
    "print(np.array(AvgRsmle).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we choose weighted KNN with manhantan distance which has the highest accuracy compared to other 3 knn performances for prediction\n",
    "test1 = testData[colName]\n",
    "test2 = test1.fillna(test1.mean())\n",
    "test3 = preprocessing.StandardScaler().fit_transform(test2)\n",
    "newPred = []\n",
    "#bagging\n",
    "for i in range(8,16):\n",
    "    newPred.append(manhantanKNN(test3, X,y,i,\"Y\"))\n",
    "Predmean = np.array(newPred).mean(axis=0)\n",
    "#convert back to normal numbers from log10\n",
    "Predmean = np.exp(Predmean)-1\n",
    "myId = pd.DataFrame(testData.Id)\n",
    "prediction = pd.DataFrame(Predmean.reshape(-1,1), columns=[\"SalePrice\"])\n",
    "prediciton2 = pd.concat([myId,prediction], axis=1,sort=False)\n",
    "prediciton2.to_csv(\"finalSubmission.csv\",index=False) #output it into a csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
